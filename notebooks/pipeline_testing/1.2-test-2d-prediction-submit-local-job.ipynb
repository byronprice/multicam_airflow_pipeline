{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19098993",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900a1f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/peromoseq/anaconda3/envs/mmdeploy/bin/python3\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import logging\n",
    "import inspect\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4930f63",
   "metadata": {},
   "source": [
    "### Get recording info (google sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63237b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5909c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spreadsheet_url = 'https://docs.google.com/spreadsheet/ccc?key=14HIqUaSl_n-91hpAvmACY_iVY9nLKdlA6qklhxfZon0&output=csv&gid=0'\n",
    "spreadsheet_url = \"https://docs.google.com/spreadsheet/ccc?key=1jACsUmxuJ9Une59qmvzZGc1qXezKhKzD1zho2sEfcrU&output=csv&gid=0\"\n",
    "response = requests.get(spreadsheet_url)\n",
    "recording_df = pd.read_csv(BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49df48f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>duration_m</th>\n",
       "      <th>video_recording_id</th>\n",
       "      <th>ephys_id</th>\n",
       "      <th>calibration_id</th>\n",
       "      <th>video_location_on_o2</th>\n",
       "      <th>ephys_location_on_o2</th>\n",
       "      <th>calibration_location_on_o2</th>\n",
       "      <th>samplerate</th>\n",
       "      <th>username</th>\n",
       "      <th>n_ephys_streams</th>\n",
       "      <th>max_video_duration_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M04002</td>\n",
       "      <td>10</td>\n",
       "      <td>24-05-01-13-26-43-110846</td>\n",
       "      <td>2024-05-01_13-26-37</td>\n",
       "      <td>24-05-01-13-45-07-825493</td>\n",
       "      <td>/n/groups/datta/tim_sainburg/datasets/chronic2...</td>\n",
       "      <td>/n/groups/datta/tim_sainburg/datasets/chronic2...</td>\n",
       "      <td>/n/groups/datta/tim_sainburg/datasets/chronic2...</td>\n",
       "      <td>150</td>\n",
       "      <td>tis697</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject  duration_m        video_recording_id             ephys_id  \\\n",
       "0  M04002          10  24-05-01-13-26-43-110846  2024-05-01_13-26-37   \n",
       "\n",
       "             calibration_id  \\\n",
       "0  24-05-01-13-45-07-825493   \n",
       "\n",
       "                                video_location_on_o2  \\\n",
       "0  /n/groups/datta/tim_sainburg/datasets/chronic2...   \n",
       "\n",
       "                                ephys_location_on_o2  \\\n",
       "0  /n/groups/datta/tim_sainburg/datasets/chronic2...   \n",
       "\n",
       "                          calibration_location_on_o2  samplerate username  \\\n",
       "0  /n/groups/datta/tim_sainburg/datasets/chronic2...         150   tis697   \n",
       "\n",
       "   n_ephys_streams  max_video_duration_m  \n",
       "0                1                    10  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c657989",
   "metadata": {},
   "source": [
    "### Submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7951d065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:multicamera_airflow_pipeline.tim_240731.interface.local:Python interpreter binary location: /home/peromoseq/anaconda3/envs/mmdeploy/bin/python3\n"
     ]
    }
   ],
   "source": [
    "from multicamera_airflow_pipeline.tim_240731.interface.local import LocalRunner\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c52b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, recording_row in recording_df.iterrows():\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0fa7af",
   "metadata": {},
   "source": [
    "### Job specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1102e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import textwrap\n",
    "import time\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34d648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are arguments\n",
    "output_directory = Path(\"/n/groups/datta/tim_sainburg/datasets/scratch/\") / \"240808-3d-pipeline\"\n",
    "job_directory = Path('/n/groups/datta/tim_sainburg/datasets/scratch/jobs')\n",
    "job_directory.mkdir(exist_ok=True, parents=True)\n",
    "config_file = Path(\"/n/groups/datta/tim_sainburg/projects/multicamera_airflow_pipeline/multicamera_airflow_pipeline/tim_240731/default_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13215951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_memory_usage(gpu_id):\n",
    "    \"\"\"\n",
    "    Returns the memory usage of a specified GPU.\n",
    "    \"\"\"\n",
    "    result = subprocess.run(\n",
    "        [\"nvidia-smi\", \"--query-gpu=memory.used\", \"--format=csv,noheader,nounits\", \"-i\", str(gpu_id)],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    return int(result.stdout.strip())\n",
    "\n",
    "def get_cuda_visible_device_with_lowest_memory():\n",
    "    \"\"\"\n",
    "    Finds the GPU with the lowest memory usage and sets CUDA_VISIBLE_DEVICES to that GPU.\n",
    "    \"\"\"\n",
    "    # Get the number of GPUs\n",
    "    result = subprocess.run(\n",
    "        [\"nvidia-smi\", \"--query-gpu=name\", \"--format=csv,noheader\"],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    gpus = result.stdout.strip().split(\"\\n\")\n",
    "    num_gpus = len(gpus)\n",
    "\n",
    "    lowest_memory_usage = None\n",
    "    best_gpu = None\n",
    "\n",
    "    for i in range(num_gpus):\n",
    "        mem_usage = get_gpu_memory_usage(i)\n",
    "        if lowest_memory_usage is None or mem_usage < lowest_memory_usage:\n",
    "            lowest_memory_usage = mem_usage\n",
    "            best_gpu = i\n",
    "\n",
    "    return best_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f35bf019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_minutes_to_hms(minutes_float):\n",
    "    # Convert minutes to total seconds\n",
    "    total_seconds = int(minutes_float * 60)\n",
    "    \n",
    "    # Extract hours, minutes, and seconds using divmod\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    \n",
    "    # Format as HH:MM:SS\n",
    "    return f\"{hours:02}:{minutes:02}:{seconds:02}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7483872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_2d_completion(output_directory_predictions):\n",
    "    return (output_directory_predictions / \"completed.log\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6fb5de4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load config\n",
    "config_file = Path(config_file)\n",
    "config = yaml.safe_load(open(config_file, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "259edaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the video data is located\n",
    "recording_directory = (\n",
    "    Path(recording_row.video_location_on_o2) / recording_row.video_recording_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c162160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where to save output\n",
    "output_directory_predictions = (\n",
    "    output_directory / \"2D_predictions\" / recording_row.video_recording_id\n",
    ")\n",
    "output_directory_predictions.mkdir(parents=True, exist_ok=True)\n",
    "current_datetime_str = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "current_job_directory = job_directory / current_datetime_str\n",
    "\n",
    "# duration of video files (useful if videos are not properly muxxed)\n",
    "expected_video_length_frames = recording_row.max_video_duration_m * 60 * recording_row.samplerate\n",
    "\n",
    "# where tensorrt compiled models are saved (specific to GPU, so we compute on the fly)\n",
    "tensorrt_model_directory = output_directory / \"tensorrt\" \n",
    "\n",
    "params = {\n",
    "    \"recording_directory\": recording_directory.as_posix(),\n",
    "    \"output_directory_predictions\": output_directory_predictions.as_posix(),\n",
    "    \"expected_video_length_frames\": expected_video_length_frames,\n",
    "    \"tensorrt_model_directory\": tensorrt_model_directory.as_posix(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85317d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/n/groups/datta/tim_sainburg/datasets/scratch/240808-3d-pipeline/tensorrt')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorrt_model_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9008c5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rtmdet_tiny_8xb32-300e_coco_chronic_24-05-04-17-51-58_216661\r\n",
      "rtmpose-m_8xb64-210e_ap10k-256x256_24-05-04-21-35-13_305524\r\n"
     ]
    }
   ],
   "source": [
    "!ls {tensorrt_model_directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "512046c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploy.json  end2end.engine  output_pytorch.jpg   pipeline.json\r\n",
      "detail.json  end2end.onnx    output_tensorrt.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!ls {tensorrt_model_directory/ \"rtmpose-m_8xb64-210e_ap10k-256x256_24-05-04-21-35-13_305524\" / \"NVIDIA_GeForce_RTX_4070_Ti\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a2e0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda_env = Path(config[\"tensorrt_conversion_local\"][\"conda_env\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5af2ebd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/peromoseq/anaconda3/envs/mmdeploy')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conda_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6c9945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "gpu_to_use = get_cuda_visible_device_with_lowest_memory()\n",
    "\n",
    "print(gpu_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "635b1d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the job runner\n",
    "runner = LocalRunner(\n",
    "    job_name_prefix=f\"{recording_row.video_recording_id}_2d_predictions\",\n",
    "    job_directory=current_job_directory,\n",
    "    conda_env=conda_env,\n",
    "    job_params=params,\n",
    "    gpu_to_use = gpu_to_use,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc1aee57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# load params\n",
      "import yaml\n",
      "params_file = \"/n/groups/datta/tim_sainburg/datasets/scratch/jobs/20240813_152436_875670/24-05-01-13-26-43-110846_2d_predictions_24-08-13-2024-24-37-366679.params.yaml\"\n",
      "config_file = \"/n/groups/datta/tim_sainburg/projects/multicamera_airflow_pipeline/multicamera_airflow_pipeline/tim_240731/default_config.yaml\"\n",
      "\n",
      "params = yaml.safe_load(open(params_file, 'r'))\n",
      "config = yaml.safe_load(open(config_file, 'r'))\n",
      "\n",
      "config[\"tensorrt_conversion\"][\"conda_env\"] = \"/home/peromoseq/anaconda3/envs/mmdeploy\"\n",
      "# convert models to tensorrt\n",
      "from multicamera_airflow_pipeline.tim_240731.keypoints.tensorrt import RTMModelConverter\n",
      "model_converter = RTMModelConverter(\n",
      "    tensorrt_output_directory = params[\"tensorrt_model_directory\"],\n",
      "    is_local=True,\n",
      "    **config[\"tensorrt_conversion\"]\n",
      ")\n",
      "model_converter.run()\n",
      "\n",
      "# run predictions\n",
      "from multicamera_airflow_pipeline.tim_240731.keypoints.predict_2D import Inferencer2D\n",
      "camera_calibrator = Inferencer2D(\n",
      "    recording_directory = params[\"recording_directory\"],\n",
      "    output_directory_predictions = params[\"output_directory_predictions\"],\n",
      "    expected_video_length_frames = params[\"expected_video_length_frames\"],\n",
      "    tensorrt_model_directory = params[\"tensorrt_model_directory\"],\n",
      "    **config[\"prediction_2d\"]\n",
      ")\n",
      "camera_calibrator.run()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if config[\"prediction_2d\"][\"use_tensorrt\"]:\n",
    "    runner.python_script = textwrap.dedent(\n",
    "        f\"\"\"\n",
    "    # load params\n",
    "    import yaml\n",
    "    params_file = \"{runner.job_directory / f\"{runner.job_name}.params.yaml\"}\"\n",
    "    config_file = \"{config_file.as_posix()}\"\n",
    "\n",
    "    params = yaml.safe_load(open(params_file, 'r'))\n",
    "    config = yaml.safe_load(open(config_file, 'r'))\n",
    "    \n",
    "    config[\"tensorrt_conversion\"][\"conda_env\"] = \"{conda_env.as_posix()}\"\n",
    "    # convert models to tensorrt\n",
    "    from multicamera_airflow_pipeline.tim_240731.keypoints.tensorrt import RTMModelConverter\n",
    "    model_converter = RTMModelConverter(\n",
    "        tensorrt_output_directory = params[\"tensorrt_model_directory\"],\n",
    "        is_local=True,\n",
    "        **config[\"tensorrt_conversion\"]\n",
    "    )\n",
    "    model_converter.run()\n",
    "    \n",
    "    # run predictions\n",
    "    from multicamera_airflow_pipeline.tim_240731.keypoints.predict_2D import Inferencer2D\n",
    "    camera_calibrator = Inferencer2D(\n",
    "        recording_directory = params[\"recording_directory\"],\n",
    "        output_directory_predictions = params[\"output_directory_predictions\"],\n",
    "        expected_video_length_frames = params[\"expected_video_length_frames\"],\n",
    "        tensorrt_model_directory = params[\"tensorrt_model_directory\"],\n",
    "        **config[\"prediction_2d\"]\n",
    "    )\n",
    "    camera_calibrator.run()\n",
    "    \"\"\"\n",
    "    )\n",
    "else:\n",
    "    runner.python_script = textwrap.dedent(\n",
    "        f\"\"\"\n",
    "    # load params\n",
    "    import yaml\n",
    "    import sys\n",
    "    print(sys.executable)\n",
    "    params_file = \"{runner.job_directory / f\"{runner.job_name}.params.yaml\"}\"\n",
    "    config_file = \"{config_file.as_posix()}\"\n",
    "\n",
    "    params = yaml.safe_load(open(params_file, 'r'))\n",
    "    config = yaml.safe_load(open(config_file, 'r'))\n",
    "\n",
    "    # grab sync cameras function\n",
    "    from multicamera_airflow_pipeline.tim_240731.keypoints.predict_2D import Inferencer2D\n",
    "    camera_calibrator = Inferencer2D(\n",
    "        recording_directory = params[\"recording_directory\"],\n",
    "        output_directory_predictions = params[\"output_directory_predictions\"],\n",
    "        expected_video_length_frames = params[\"expected_video_length_frames\"],\n",
    "        tensorrt_model_directory = params[\"tensorrt_model_directory\"],\n",
    "        **config[\"prediction_2d\"]\n",
    "    )\n",
    "    camera_calibrator.run()\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "print(runner.python_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7992756b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:multicamera_airflow_pipeline.tim_240731.interface.local:Creating remote job directory: /n/groups/datta/tim_sainburg/datasets/scratch/jobs/20240813_152436_875670\n",
      "INFO:multicamera_airflow_pipeline.tim_240731.interface.local:Writing job script, python script, params\n",
      "INFO:multicamera_airflow_pipeline.tim_240731.interface.local:Using GPU 0\n",
      "INFO:multicamera_airflow_pipeline.tim_240731.interface.local:Submitting job\n",
      "INFO:multicamera_airflow_pipeline.tim_240731.interface.local:loading libmmdeploy_trt_net.so ...\n",
      "\n",
      "INFO:multicamera_airflow_pipeline.tim_240731.interface.local:loading libmmdeploy_ort_net.so ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a7eae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd13034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdeploy",
   "language": "python",
   "name": "mmdeploy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
